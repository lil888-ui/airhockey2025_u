{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a01d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import mujoco\n",
    "import numpy as np\n",
    "from gymnasium.envs.mujoco import MujocoEnv\n",
    "from gymnasium import spaces\n",
    "from gymnasium.spaces import Box\n",
    "from typing import Dict, Union\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "DEFAULT_CAMERA_CONFIG = {\n",
    "    \"trackbodyid\": -1,\n",
    "    \"distance\": 4.0,\n",
    "}\n",
    "\n",
    "class MyRobotEnv(MujocoEnv):\n",
    "    def __init__(\n",
    "        self, \n",
    "        xml_path = \"/workspace/ros2_ws/src/airhockey2025/ka/assets/main.xml\",\n",
    "        frame_skip: int = 5,\n",
    "        default_camera_config: Dict[str, Union[float, int]] = DEFAULT_CAMERA_CONFIG,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # 一度モデルを読み込んで観測次元を取得\n",
    "        model = mujoco.MjModel.from_xml_path(xml_path)\n",
    "        obs_dim = model.nq + model.nv\n",
    "        observation_space = Box(low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32)\n",
    "\n",
    "        # 行動空間：joint velocities [-1, 1] 正規化\n",
    "        # 現状はmodelのアクチュエータが認識していないので、model.nuがなくなっている\n",
    "        # そのため, model.ctrlもないのでstepができない状態\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-1.0, high=1.0, shape=model.actuator_actnum.shape, dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # 親クラスの初期化\n",
    "        super().__init__(\n",
    "            model_path=xml_path,\n",
    "            frame_skip=frame_skip,\n",
    "            observation_space=observation_space,\n",
    "            render_mode=\"rgb_array\",\n",
    "            default_camera_config=default_camera_config,\n",
    "            **kwargs,\n",
    "        )\n",
    "        \n",
    "        self.metadata = {\n",
    "            \"render_modes\": [\n",
    "                \"human\",\n",
    "                \"rgb_array\",\n",
    "                \"depth_array\",\n",
    "                \"rgbd_tuple\",\n",
    "            ],\n",
    "            \"render_fps\": int(np.round(1.0 / self.dt)),\n",
    "        }\n",
    "\n",
    "    def step(self, action):\n",
    "        # 正規化されたactionをスケーリング\n",
    "        scaled_action = action * self.model.actuator_ctrlrange[:, 1]\n",
    "        self.do_simulation(scaled_action, self.frame_skip)\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        reward = self._compute_reward(obs, action)\n",
    "        done = False\n",
    "        info = {}\n",
    "\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return np.concatenate([self.data.qpos.flat, self.data.qvel.flat])\n",
    "\n",
    "    def _compute_reward(self, obs, action):\n",
    "        # エンドエフェクタの位置を使用した報酬例\n",
    "        # end_effector_pos = self.data.site_xpos[self.model.site_name2id(\"ee_site\")]\n",
    "        # goal = np.array([0.5, 0.0, 0.2])\n",
    "        # dist = np.linalg.norm(end_effector_pos - goal)\n",
    "        # return -dist\n",
    "        return 0\n",
    "\n",
    "    def reset_model(self):\n",
    "        # ランダム初期化\n",
    "        qpos = self.init_qpos + np.random.uniform(-0.01, 0.01, size=self.model.nq)\n",
    "        qvel = self.init_qvel + np.random.uniform(-0.01, 0.01, size=self.model.nv)\n",
    "        self.set_state(qpos, qvel)\n",
    "        return self._get_obs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bde0238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(images):\n",
    "    for img in images:\n",
    "        # 画像をuint8のBGRに変換（OpenCV用）\n",
    "        img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        cv2.imshow('Video', img_bgr)\n",
    "        if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d17b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MyRobotEnv()\n",
    "env.reset()\n",
    "images = []\n",
    "skip_frame = 5\n",
    "\n",
    "for i in range(1000):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    if i % skip_frame == 0:\n",
    "        images.append(env.render())\n",
    "\n",
    "render(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
